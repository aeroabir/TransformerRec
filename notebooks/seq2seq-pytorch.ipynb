{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer seq2seq Model\n",
    "\n",
    "- Modified from https://github.com/bentrevett/pytorch-seq2seq\n",
    "- also useful: https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "\n",
    "import torchtext\n",
    "# from torchtext.legacy.datasets import Multi30k\n",
    "# from torchtext.legacy.data import Field, BucketIterator\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# import spacy\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer_pyt import Encoder, Decoder, Seq2Seq, Seq2SeqMulti, Seq2Class, SimpleDecoder\n",
    "from transformer_pyt import train, evaluate\n",
    "from utils import (get_session_data, \n",
    "                   build_vocab_from_seqs, \n",
    "                   data_process_meta, \n",
    "                   data_process_no_meta,\n",
    "                   epoch_time,\n",
    "                   get_session_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0924243001',\n",
       " '0924243002',\n",
       " '0923758001',\n",
       " '0918522001',\n",
       " '0909370001',\n",
       " '0866731001',\n",
       " '0751471001',\n",
       " '0915529003',\n",
       " '0915529005',\n",
       " '0448509014',\n",
       " '0762846027',\n",
       " '0714790020']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/recsys_data/RecSys/h_and_m_personalized_fashion_recommendation\"\n",
    "file_name = \"hnm_3w_sessionized_orig.txt\" # \"hnm_big.txt\", \"hnm_3w_sessionized.txt\", \"hnm_7w_sessionized.txt\"\n",
    "seq_file_name = \"seq_\" + file_name\n",
    "test_seq_file = \"seq_test_\" + file_name\n",
    "colsep = \"\\t\"\n",
    "include_meta = False\n",
    "model_type = \"seq2class\"  # \"seq2seq\", \"seq2class\"\n",
    "model_name = file_name.split(\".\")[0] + \"_\" + model_type + \".pt\"\n",
    "\n",
    "inp_seq_len, tgt_seq_len = 12, 12\n",
    "BATCH_SIZE = 256\n",
    "num_examples = None\n",
    "file_path = os.path.join(data_dir, seq_file_name)\n",
    "model_path = os.path.join(data_dir, model_name)\n",
    "test_file_path = os.path.join(data_dir, test_seq_file)\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "# en_tokenizer = get_tokenizer(language='en')\n",
    "\n",
    "tokens = tokenizer('0924243001 0924243002 0923758001 0918522001 0909370001 0866731001 0751471001 0915529003 0915529005 0448509014 0762846027 0714790020')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the sequence information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364695it [00:02, 163209.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 48709 user interactions\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 'prod'])\n"
     ]
    }
   ],
   "source": [
    "inp_file = os.path.join(data_dir, file_name)\n",
    "\n",
    "all_seqs, prod_dict = get_session_data(inp_file, \n",
    "                                       inp_seq_len=inp_seq_len,\n",
    "                                       tgt_seq_len=tgt_seq_len,\n",
    "                                       convert_to_integer=False)\n",
    "print(all_seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0921073001'], ['0777148006', '0835801001', '0923134005', '0865929003'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_seqs['prod'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 21532 words in the vocabulary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(71460, 57168, 14292)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = build_vocab_from_seqs(all_seqs['prod'], tokenizer, extra=[\"<pad>\", \"<bos>\", \"<eos>\"])\n",
    "print(f\"Total {len(src_vocab)} words in the vocabulary\")\n",
    "\n",
    "if include_meta:\n",
    "    all_data = data_process_meta(all_seqs, tokenizer, src_vocab)\n",
    "else:\n",
    "    all_data = data_process_no_meta(all_seqs, src_vocab)\n",
    "train_data, val_data = train_test_split(all_data, test_size=0.2)\n",
    "# test_data = data_process(test_file_path, tokenizer, src_vocab, test_flag=True)\n",
    "len(all_data), len(train_data), len(val_data)#, len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 0, 1, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['<unk>'], src_vocab['<pad>'], src_vocab['<bos>'], src_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(980, 12650, 21532)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['0921073001'], src_vocab['0777148006'], len(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12909,  7398]),\n",
       " tensor([  52,    5, 1069,   25,   25,  208, 3076, 3076,   15,  169]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Product Vector - Separately Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105542, 50) 105542\n"
     ]
    }
   ],
   "source": [
    "pv_file = os.path.join(data_dir, \"prod_vectors.pkl\")\n",
    "with open(pv_file, \"rb\") as fr:\n",
    "    prod_vec, prod_list = pickle.load(fr)\n",
    "print(prod_vec.shape, len(prod_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "embed_matrix = np.zeros((len(src_vocab), prod_vec.shape[1]))\n",
    "count = 0\n",
    "for tok, idx in src_vocab.stoi.items():\n",
    "    if tok in prod_list:\n",
    "        list_index = prod_list.index(tok)\n",
    "        embed_matrix[idx] = prod_vec[list_index]\n",
    "    else:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = src_vocab['<pad>']\n",
    "BOS_IDX = src_vocab['<bos>']\n",
    "EOS_IDX = src_vocab['<eos>']\n",
    "\n",
    "if include_meta:\n",
    "    def generate_batch(data_batch):\n",
    "        inp_batch, tgt_batch = [], []\n",
    "        for (de_item, en_item) in data_batch:\n",
    "            n = de_item.shape[0]\n",
    "            before = torch.unsqueeze(torch.tensor([BOS_IDX] * n), 1)\n",
    "            after = torch.unsqueeze(torch.tensor([EOS_IDX] * n), 1)\n",
    "            total = torch.cat([before, de_item, after], dim=1)\n",
    "            total = total.permute(1, 0)\n",
    "            inp_batch.append(total)\n",
    "            tgt_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "\n",
    "        inp_batch = pad_sequence(inp_batch, padding_value=PAD_IDX)\n",
    "        tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "        return inp_batch, tgt_batch\n",
    "\n",
    "    # input dimension of each product attribute\n",
    "    prod_dict_dims = [max(prod_dict[k].values()) for k in range(len(prod_dict))]\n",
    "\n",
    "else:\n",
    "    def generate_batch(data_batch):\n",
    "        de_batch, en_batch = [], []\n",
    "        for (de_item, en_item) in data_batch:\n",
    "            de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "            en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "        en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "        return de_batch, en_batch\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iterator = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 256]) torch.Size([14, 256])\n",
      "tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [4499,   92, 5340,  ...,  269,  204, 1452],\n",
      "        [2932,  105, 2700,  ..., 7063,   51,    2],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]])\n",
      "tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [  223,   212,   130,  ...,    63, 10590,   380],\n",
      "        [ 1196,   468,    77,  ...,   125,  7063,     2],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "src, trg = next(iter(train_iterator))\n",
    "print(src.shape, trg.shape)\n",
    "print(src)\n",
    "print(trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multiple encoders - one for each product attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = 0\n",
    "TRG_PAD_IDX = 0\n",
    "\n",
    "if include_meta:\n",
    "    HID_DIM = 128\n",
    "    HID_DIM2 = 32\n",
    "    ENC_LAYERS = 2\n",
    "    DEC_LAYERS = 2\n",
    "    ENC_HEADS = 8\n",
    "    DEC_HEADS = 8\n",
    "    ENC_PF_DIM = 128\n",
    "    DEC_PF_DIM = 128\n",
    "    ENC_DROPOUT = 0.1\n",
    "    DEC_DROPOUT = 0.1\n",
    "    OUTPUT_DIM = len(src_vocab)\n",
    "\n",
    "    encs = torch.nn.ModuleList()\n",
    "    prod_enc = Encoder(input_dim=len(src_vocab), \n",
    "                       hid_dim=HID_DIM, \n",
    "                       n_layers=ENC_LAYERS, \n",
    "                       n_heads=ENC_HEADS, \n",
    "                       pf_dim=ENC_PF_DIM, \n",
    "                       dropout=ENC_DROPOUT, \n",
    "                       device=device)\n",
    "    encs.append(prod_enc)\n",
    "    total_dim = HID_DIM\n",
    "    for pdim in prod_dict_dims:\n",
    "        enc_p = Encoder(input_dim=pdim, \n",
    "                       hid_dim=HID_DIM2, \n",
    "                       n_layers=ENC_LAYERS, \n",
    "                       n_heads=ENC_HEADS, \n",
    "                       pf_dim=ENC_PF_DIM, \n",
    "                       dropout=ENC_DROPOUT, \n",
    "                       device=device)\n",
    "        encs.append(enc_p)\n",
    "        total_dim += HID_DIM2\n",
    "\n",
    "    dec = Decoder(OUTPUT_DIM, \n",
    "                  HID_DIM, \n",
    "                  DEC_LAYERS, \n",
    "                  DEC_HEADS, \n",
    "                  DEC_PF_DIM, \n",
    "                  DEC_DROPOUT, \n",
    "                  device)\n",
    "    model = Seq2SeqMulti(encs, dec, total_dim, HID_DIM, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)    \n",
    "else:\n",
    "    INPUT_DIM = len(src_vocab)\n",
    "    OUTPUT_DIM = len(src_vocab)\n",
    "    HID_DIM = 256\n",
    "    ENC_LAYERS = 3\n",
    "    DEC_LAYERS = 3\n",
    "    ENC_HEADS = 8\n",
    "    DEC_HEADS = 8\n",
    "    ENC_PF_DIM = 512\n",
    "    DEC_PF_DIM = 512\n",
    "    ENC_DROPOUT = 0.1\n",
    "    DEC_DROPOUT = 0.1\n",
    "\n",
    "    enc = Encoder(INPUT_DIM, \n",
    "                  HID_DIM, \n",
    "                  ENC_LAYERS, \n",
    "                  ENC_HEADS, \n",
    "                  ENC_PF_DIM, \n",
    "                  ENC_DROPOUT, \n",
    "                  device,\n",
    "                  pretrained=True,\n",
    "                  weight=torch.FloatTensor(embed_matrix),  # has to be converted\n",
    "                  ext_embed_dim=embed_matrix.shape[1])\n",
    "\n",
    "    if model_type == \"seq2class\":\n",
    "        dec = SimpleDecoder(OUTPUT_DIM, \n",
    "                            HID_DIM,\n",
    "                            inp_seq_len+2,\n",
    "                            tgt_seq_len+2,\n",
    "                            DEC_DROPOUT)\n",
    "        model = Seq2Class(enc, dec, SRC_PAD_IDX, device).to(device)\n",
    "    else:\n",
    "        dec = Decoder(OUTPUT_DIM, \n",
    "                      HID_DIM, \n",
    "                      DEC_LAYERS, \n",
    "                      DEC_HEADS, \n",
    "                      DEC_PF_DIM, \n",
    "                      DEC_DROPOUT, \n",
    "                      device)\n",
    "        model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,154,414 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        \n",
    "model.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps per epoch: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:38,  5.79it/s]\n",
      "56it [00:04, 13.75it/s]\n",
      "1it [00:00,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 42s | patience 0\n",
      "\tTrain Loss: 8.294 | Train PPL: 3999.802\n",
      "\t Val. Loss: 6.885 |  Val. PPL: 977.736 | Val. MAP:   0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.74it/s]\n",
      "56it [00:04, 13.92it/s]\n",
      "1it [00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 43s | patience 0\n",
      "\tTrain Loss: 6.520 | Train PPL: 678.802\n",
      "\t Val. Loss: 6.134 |  Val. PPL: 461.280 | Val. MAP:   0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.71it/s]\n",
      "56it [00:04, 13.82it/s]\n",
      "1it [00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 43s | patience 0\n",
      "\tTrain Loss: 5.624 | Train PPL: 277.103\n",
      "\t Val. Loss: 5.547 |  Val. PPL: 256.415 | Val. MAP:   0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.70it/s]\n",
      "56it [00:04, 13.80it/s]\n",
      "1it [00:00,  5.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 43s | patience 0\n",
      "\tTrain Loss: 5.400 | Train PPL: 221.302\n",
      "\t Val. Loss: 5.533 |  Val. PPL: 252.955 | Val. MAP:   0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.70it/s]\n",
      "56it [00:04, 13.38it/s]\n",
      "1it [00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 43s | patience 1\n",
      "\tTrain Loss: 5.372 | Train PPL: 215.394\n",
      "\t Val. Loss: 5.534 |  Val. PPL: 253.114 | Val. MAP:   0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.68it/s]\n",
      "56it [00:04, 13.57it/s]\n",
      "1it [00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 43s | patience 0\n",
      "\tTrain Loss: 5.358 | Train PPL: 212.205\n",
      "\t Val. Loss: 5.532 |  Val. PPL: 252.652 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.68it/s]\n",
      "56it [00:04, 13.90it/s]\n",
      "1it [00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 43s | patience 0\n",
      "\tTrain Loss: 5.345 | Train PPL: 209.588\n",
      "\t Val. Loss: 5.531 |  Val. PPL: 252.483 | Val. MAP:   0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.70it/s]\n",
      "56it [00:04, 13.65it/s]\n",
      "1it [00:00,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 43s | patience 1\n",
      "\tTrain Loss: 5.335 | Train PPL: 207.391\n",
      "\t Val. Loss: 5.541 |  Val. PPL: 254.970 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.71it/s]\n",
      "56it [00:04, 13.62it/s]\n",
      "1it [00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 43s | patience 2\n",
      "\tTrain Loss: 5.322 | Train PPL: 204.699\n",
      "\t Val. Loss: 5.546 |  Val. PPL: 256.316 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.68it/s]\n",
      "56it [00:04, 13.78it/s]\n",
      "1it [00:00,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 43s | patience 3\n",
      "\tTrain Loss: 5.310 | Train PPL: 202.412\n",
      "\t Val. Loss: 5.560 |  Val. PPL: 259.801 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.70it/s]\n",
      "56it [00:04, 13.53it/s]\n",
      "1it [00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 0m 43s | patience 4\n",
      "\tTrain Loss: 5.301 | Train PPL: 200.561\n",
      "\t Val. Loss: 5.567 |  Val. PPL: 261.681 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.70it/s]\n",
      "56it [00:04, 13.73it/s]\n",
      "1it [00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 0m 43s | patience 5\n",
      "\tTrain Loss: 5.291 | Train PPL: 198.446\n",
      "\t Val. Loss: 5.567 |  Val. PPL: 261.619 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.70it/s]\n",
      "56it [00:04, 13.92it/s]\n",
      "1it [00:00,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 0m 43s | patience 6\n",
      "\tTrain Loss: 5.279 | Train PPL: 196.223\n",
      "\t Val. Loss: 5.579 |  Val. PPL: 264.916 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.70it/s]\n",
      "56it [00:04, 13.43it/s]\n",
      "1it [00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 0m 43s | patience 7\n",
      "\tTrain Loss: 5.270 | Train PPL: 194.319\n",
      "\t Val. Loss: 5.586 |  Val. PPL: 266.765 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.69it/s]\n",
      "56it [00:04, 13.71it/s]\n",
      "1it [00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 0m 43s | patience 8\n",
      "\tTrain Loss: 5.259 | Train PPL: 192.347\n",
      "\t Val. Loss: 5.594 |  Val. PPL: 268.903 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.69it/s]\n",
      "56it [00:04, 13.70it/s]\n",
      "1it [00:00,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 0m 43s | patience 9\n",
      "\tTrain Loss: 5.250 | Train PPL: 190.536\n",
      "\t Val. Loss: 5.598 |  Val. PPL: 269.834 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:39,  5.69it/s]\n",
      "56it [00:04, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum patience reached ... exiting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-04\n",
    "CLIP = 1\n",
    "patience, max_patience = 0, 10\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_map = 0\n",
    "\n",
    "print(f\"Number of steps per epoch: {len(train_data)//BATCH_SIZE}\")\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, device)\n",
    "    valid_loss, valid_map = evaluate(model, valid_iterator, criterion, device)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "#     if valid_map > best_valid_map:\n",
    "    if valid_loss < best_valid_loss:\n",
    "#         best_valid_map = valid_map\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "\n",
    "    if patience == max_patience:\n",
    "        print(\"Maximum patience reached ... exiting!\")\n",
    "        break\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s | patience {patience}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f} | Val. MAP: {valid_map:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_pyt import map_batch, mAP_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:04, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005455325555929919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "valid_loss, valid_map = evaluate(model, valid_iterator, criterion, device)\n",
    "print(valid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.00390625\n",
      "0.0078125\n",
      "0.0078125\n",
      "0.0078125\n",
      "0.0\n",
      "0.0078125\n",
      "0.0078125\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.0\n",
      "0.00390625\n",
      "0.0078125\n",
      "0.0078125\n",
      "0.0\n",
      "0.00390625\n",
      "0.0\n",
      "0.00390625\n",
      "0.01171875\n",
      "0.0\n",
      "0.00390625\n",
      "0.01171875\n",
      "0.0078125\n",
      "0.01171875\n",
      "0.00390625\n",
      "0.0\n",
      "0.0\n",
      "0.00390625\n",
      "0.015625\n",
      "0.00390625\n",
      "0.0\n",
      "0.00390625\n",
      "0.00390625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.00390625\n",
      "0.0078125\n",
      "0.01171875\n",
      "0.01171875\n",
      "0.01953125\n",
      "0.01171875\n",
      "0.00390625\n",
      "0.00390625\n",
      "0.0\n",
      "0.0\n",
      "0.00390625\n",
      "0.00390625\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.0078125\n",
      "0.0078125\n",
      "0.0\n",
      "0.0078125\n",
      "0.00390625\n",
      "0.0078125\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for _, (src, trg) in enumerate(valid_iterator):\n",
    "    src, trg = src.to(device), trg.to(device)\n",
    "    if src.dim() == 3:\n",
    "        src = src.permute(1, 0, 2)\n",
    "    else:\n",
    "        src = src.permute(1, 0)\n",
    "    trg = trg.permute(1, 0)\n",
    "\n",
    "    output, _ = model(src, trg[:, :-1])\n",
    "    prediction = torch.argmax(output, axis=-1)\n",
    "    mapr = map_batch(trg[:, 1:], prediction)\n",
    "    print(mapr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 2,  ..., 2, 2, 2],\n",
       "        [1, 3, 2,  ..., 2, 2, 2],\n",
       "        [1, 3, 2,  ..., 2, 2, 2],\n",
       "        ...,\n",
       "        [1, 3, 2,  ..., 2, 2, 2],\n",
       "        [1, 3, 2,  ..., 2, 2, 2],\n",
       "        [1, 3, 2,  ..., 2, 2, 2]], device='cuda:0', grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1579,    2,    0,  ...,    0,    0,    0],\n",
       "        [  88,  310,    2,  ...,    0,    0,    0],\n",
       "        [2595,    2,    0,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [5322,    2,    0,  ...,    0,    0,    0],\n",
       "        [ 219, 1061, 1292,  ...,    0,    0,    0],\n",
       "        [3275,    2,    0,  ...,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = trg[:, 1:]\n",
    "pred = prediction.cpu().numpy()\n",
    "label = label.cpu().numpy()\n",
    "    \n",
    "for ii in range(prediction.shape[0]):\n",
    "    l_ii = [x for x in label[ii, :] if x not in [0, 1, 2]]\n",
    "    p_ii = [x for x in pred[ii, :] if x not in [0, 1, 2]]\n",
    "    if mAP_k(l_ii, p_ii) > 0:\n",
    "        print(l_ii, p_ii, mAP_k(l_ii, p_ii))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the test data - last session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364695it [00:02, 169774.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 48709 user interactions\n",
      "10 dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 'prod'])\n"
     ]
    }
   ],
   "source": [
    "test_seqs = get_session_data_test(inp_file, prod_dict, inp_seq_len=inp_seq_len)\n",
    "print(len(test_seqs), test_seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48709"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if include_meta:\n",
    "    def generate_batch_test(data_batch):\n",
    "        inp_batch = []\n",
    "        for de_item in data_batch:\n",
    "            n = de_item.shape[0]\n",
    "            before = torch.unsqueeze(torch.tensor([BOS_IDX] * n), 1)\n",
    "            after = torch.unsqueeze(torch.tensor([EOS_IDX] * n), 1)\n",
    "            total = torch.cat([before, de_item, after], dim=1)\n",
    "            total = total.permute(1, 0)\n",
    "            inp_batch.append(total)\n",
    "\n",
    "        inp_batch = pad_sequence(inp_batch, padding_value=PAD_IDX)\n",
    "        return inp_batch\n",
    "    \n",
    "    test_data = data_process_meta(test_seqs, tokenizer, src_vocab, test_flag=True)\n",
    "else:\n",
    "    def generate_batch_test(data_batch):\n",
    "        de_batch = []\n",
    "        for de_item in data_batch:\n",
    "            de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "        return de_batch\n",
    "    test_data = data_process_no_meta(test_seqs, src_vocab, test_flag=True)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-702649ad46e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trg' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "epoch_loss = 0\n",
    "all_maps = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for _, src in tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = src.to(device)\n",
    "        # make the batch dimension first\n",
    "        if src.dim() == 3:\n",
    "            src = src.permute(1, 0, 2)\n",
    "        else:\n",
    "            src = src.permute(1, 0)\n",
    "\n",
    "        output, _ = model(src, trg[:, :-1])\n",
    "        prediction = torch.argmax(output, axis=-1)\n",
    "        print(prediction.shape)\n",
    "        sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 14])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(src, model, vocab, device, max_len = 50):\n",
    "    \"\"\"\n",
    "    inp: (b, s, f), batch_size X sequence length X feature dimension\n",
    "    \"\"\"\n",
    "    src = src.unsqueeze(0).to(device)  # add the batch dimension\n",
    "    \n",
    "    model.eval()\n",
    "    if src.dim() == 3:\n",
    "        src_mask = model.make_src_mask(src[:, :, 0])\n",
    "    else:\n",
    "        src_mask = model.make_src_mask(src)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if src.dim() == 3:\n",
    "            enc_src = []\n",
    "            for ii in range(model.num_features):\n",
    "                enc_src.append(model.encoders[ii](src_tensor[:, :, ii], src_mask))\n",
    "            enc_src = torch.cat(enc_src, dim=-1)\n",
    "            enc_src = model.linear(enc_src)\n",
    "        else:\n",
    "            enc_src = model.encoder(src, src_mask)\n",
    "\n",
    "    trg_indexes = [vocab.stoi['<bos>']]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == vocab.stoi['<eos>']:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [vocab.itos[i] for i in trg_indexes]\n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, Tensor found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-6630a20a2e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, Tensor found"
     ]
    }
   ],
   "source": [
    "for ii in range(src.shape[0]):\n",
    "    pred, _ = translate_sentence(src[ii, :], model, src_vocab, device, max_len = tgt_seq_len)\n",
    "    print(' '.join(src[ii, :]), ' '.join(pred[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['220', '<eos>']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, _ = translate_sentence(src[4, :, :], model, src_vocab, device, max_len = tgt_seq_len)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Product Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71460, 57168, 14292, 48709)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = build_vocab_from_file(file_path, tokenizer)\n",
    "all_data = data_process(file_path, tokenizer, src_vocab)\n",
    "train_data, val_data = train_test_split(all_data, test_size=0.2)\n",
    "test_data = data_process(test_file_path, tokenizer, src_vocab, test_flag=True)\n",
    "len(all_data), len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src_vocab)\n",
    "OUTPUT_DIM = len(src_vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = src_vocab['<pad>']\n",
    "BOS_IDX = src_vocab['<bos>']\n",
    "EOS_IDX = src_vocab['<eos>']\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    return de_batch, en_batch\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iterator = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_iterator = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=False, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = 0\n",
    "TRG_PAD_IDX = 0\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, src_vocab, trg_vocab, model, device, max_len = tgt_seq_len):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    tokens = tokenizer(sentence)\n",
    "    tokens = [src_vocab['<bos>']] + tokens + [src_vocab['<eos>']]\n",
    "    src_indexes = [src_vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    trg_indexes = [trg_vocab.stoi['<bos>']]\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == trg_vocab.stoi['<eos>']:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1566', '<eos>']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, _ = predict('13112 16042 3871 35', src_vocab, src_vocab, model, device)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (torch)",
   "language": "python",
   "name": "py37_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
