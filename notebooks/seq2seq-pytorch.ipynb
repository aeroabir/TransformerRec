{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer seq2seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "\n",
    "import torchtext\n",
    "# from torchtext.legacy.datasets import Multi30k\n",
    "# from torchtext.legacy.data import Field, BucketIterator\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# import spacy\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer_pyt import Encoder, Decoder, Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0924243001',\n",
       " '0924243002',\n",
       " '0923758001',\n",
       " '0918522001',\n",
       " '0909370001',\n",
       " '0866731001',\n",
       " '0751471001',\n",
       " '0915529003',\n",
       " '0915529005',\n",
       " '0448509014',\n",
       " '0762846027',\n",
       " '0714790020']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/recsys_data/RecSys/h_and_m_personalized_fashion_recommendation\"\n",
    "file_name = \"hnm_3w_sessionized.txt\" # \"hnm_big.txt\"\n",
    "seq_file_name = \"seq_\" + file_name\n",
    "test_seq_file = \"seq_test_\" + file_name\n",
    "colsep = \"\\t\"\n",
    "\n",
    "inp_seq_len, tgt_seq_len = 12, 12\n",
    "BATCH_SIZE = 256\n",
    "num_examples = None\n",
    "file_path = os.path.join(data_dir, seq_file_name)\n",
    "test_file_path = os.path.join(data_dir, test_seq_file)\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "# en_tokenizer = get_tokenizer(language='en')\n",
    "\n",
    "tokens = tokenizer('0924243001 0924243002 0923758001 0918522001 0909370001 0866731001 0751471001 0915529003 0915529005 0448509014 0762846027 0714790020')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(filepath, tokenizer, index=-1):\n",
    "    counter = Counter()\n",
    "    with io.open(filepath, encoding=\"utf8\") as f:\n",
    "        for string_ in f:\n",
    "            if index == -1:\n",
    "                counter.update(tokenizer(string_.strip().split('\\t')[0]))\n",
    "                counter.update(tokenizer(string_.strip().split('\\t')[1]))\n",
    "            else:\n",
    "                counter.update(tokenizer(string_.strip().split('\\t')[index]))\n",
    "    return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "def data_process(filepath, tokenizer, vocab, test_flag=False):\n",
    "    raw_iter = iter(io.open(filepath, encoding=\"utf8\"))\n",
    "    data = []\n",
    "    for raw in raw_iter:\n",
    "        if test_flag:\n",
    "            src = raw.strip()\n",
    "            src_tensor = torch.tensor([vocab[token] for token in tokenizer(src)], dtype=torch.long)\n",
    "            data.append(src_tensor)\n",
    "        else:\n",
    "            src, tgt = raw.strip().split('\\t')\n",
    "            src_tensor = torch.tensor([vocab[token] for token in tokenizer(src)], dtype=torch.long)\n",
    "            tgt_tensor = torch.tensor([vocab[token] for token in tokenizer(tgt)], dtype=torch.long)\n",
    "            data.append((src_tensor, tgt_tensor))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71460, 57168, 14292, 48709)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = build_vocab(file_path, tokenizer)\n",
    "all_data = data_process(file_path, tokenizer, src_vocab)\n",
    "train_data, val_data = train_test_split(all_data, test_size=0.2)\n",
    "test_data = data_process(test_file_path, tokenizer, src_vocab, test_flag=True)\n",
    "len(all_data), len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['<unk>'], src_vocab['<pad>'], src_vocab['<bos>'], src_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = src_vocab['<pad>']\n",
    "BOS_IDX = src_vocab['<bos>']\n",
    "EOS_IDX = src_vocab['<eos>']\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    return de_batch, en_batch\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iterator = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_iterator = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=False, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src_vocab)\n",
    "OUTPUT_DIM = len(src_vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = 0\n",
    "TRG_PAD_IDX = 0\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 20,510,680 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for _, (src, trg) in tqdm(enumerate(iterator)):\n",
    "  \n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        src = src.permute(1, 0)\n",
    "        trg = trg.permute(1, 0)\n",
    "#         print(src.shape, trg.shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = model(src, trg[:,:-1])\n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    all_maps = []    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for _, (src, trg) in tqdm(enumerate(iterator)):\n",
    "\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            src = src.permute(1, 0)\n",
    "            trg = trg.permute(1, 0)\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1])\n",
    "\n",
    "            # Mean Average Precision Calculation\n",
    "            prediction = torch.argmax(output, axis=-1)\n",
    "            mapr = map_batch(trg[:,1:], prediction)\n",
    "            all_maps.append(mapr)\n",
    "                \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), np.mean(all_maps)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def rel(true, pred):\n",
    "    return 1 if true == pred else 0\n",
    "\n",
    "\n",
    "def precision_k(actual, predicted, k) -> float:\n",
    "    actual_set = set(actual[:k])\n",
    "    predicted_set = set(predicted[:k])\n",
    "    precision_k_value = len(actual_set & predicted_set) / k\n",
    "\n",
    "    return precision_k_value\n",
    "\n",
    "\n",
    "def mAP_k(actual, predicted) -> float:\n",
    "    # actual = row['valid_true'].split() # prediction_string --> prediction list\n",
    "    # predicted = row['valid_pred'].split() # prediction_string --> prediction list\n",
    "\n",
    "    M = min(len(actual), len(predicted))\n",
    "    K = min(M, 12)\n",
    "\n",
    "    if M == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        score = 0\n",
    "        for k in range(1, K + 1):\n",
    "            precision_k_value = precision_k(actual, predicted, k)\n",
    "\n",
    "            score += precision_k_value * rel(actual[k - 1], predicted[k - 1])\n",
    "        return score\n",
    "\n",
    "\n",
    "def map_batch(label, prediction):\n",
    "    \"\"\"\n",
    "    label: (batch, 12)\n",
    "    prediction: (batch, 12)\n",
    "    \"\"\"\n",
    "    pred = prediction.cpu().numpy()\n",
    "    label = label.cpu().numpy()\n",
    "    maps = []\n",
    "    for ii in range(prediction.shape[0]):\n",
    "        l_ii = [x for x in label[ii,:] if x not in [0, 1, 2, 3]]\n",
    "        p_ii = [x for x in pred[ii,:] if x not in [0, 1, 2, 3]]\n",
    "        if len(p_ii) > 0:\n",
    "            maps.append(mAP_k(l_ii, p_ii))\n",
    "        else:\n",
    "            maps.append(0)\n",
    "    return np.mean(maps)\n",
    "\n",
    "\n",
    "def evaluate_map(model, iterator):\n",
    "    \n",
    "    model.eval()\n",
    "    all_maps = []\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for _, (src, trg) in tqdm(enumerate(iterator)):\n",
    "\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "            src = src.permute(1, 0)\n",
    "            trg = trg.permute(1, 0)\n",
    "\n",
    "            logits, _ = model(src, trg[:,:-1])\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            trg = trg[:,1:]\n",
    "            prediction = torch.argmax(logits, axis=-1)\n",
    "            mapr = map_batch(trg, prediction)\n",
    "            all_maps.append(mapr)\n",
    "        \n",
    "    return np.mean(all_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:54,  4.12it/s]\n",
      "56it [00:04, 11.64it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 59s\n",
      "\tTrain Loss: 0.862 | Train PPL:   2.367\n",
      "\t Val. Loss: 2.257 |  Val. PPL:   9.551 | Val. MAP:   0.053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:54,  4.11it/s]\n",
      "56it [00:04, 11.51it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 59s\n",
      "\tTrain Loss: 0.801 | Train PPL:   2.227\n",
      "\t Val. Loss: 2.322 |  Val. PPL:  10.195 | Val. MAP:   0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:54,  4.09it/s]\n",
      "56it [00:04, 11.57it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 59s\n",
      "\tTrain Loss: 0.746 | Train PPL:   2.109\n",
      "\t Val. Loss: 2.380 |  Val. PPL:  10.808 | Val. MAP:   0.043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:54,  4.10it/s]\n",
      "56it [00:04, 11.37it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 59s\n",
      "\tTrain Loss: 0.695 | Train PPL:   2.004\n",
      "\t Val. Loss: 2.438 |  Val. PPL:  11.453 | Val. MAP:   0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:54,  4.10it/s]\n",
      "56it [00:04, 11.52it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 59s\n",
      "\tTrain Loss: 0.655 | Train PPL:   1.925\n",
      "\t Val. Loss: 2.496 |  Val. PPL:  12.135 | Val. MAP:   0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:54,  4.10it/s]\n",
      "56it [00:04, 11.57it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 59s\n",
      "\tTrain Loss: 0.616 | Train PPL:   1.852\n",
      "\t Val. Loss: 2.551 |  Val. PPL:  12.820 | Val. MAP:   0.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:19,  4.05it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-8abe7f9ce838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-417fcf47cc85>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py37_pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss, valid_map = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f} | Val. MAP: {valid_map:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, src_vocab, trg_vocab, model, device, max_len = tgt_seq_len):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    tokens = tokenizer(sentence)\n",
    "    tokens = [src_vocab['<bos>']] + tokens + [src_vocab['<eos>']]\n",
    "    src_indexes = [src_vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    trg_indexes = [trg_vocab.stoi['<bos>']]\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == trg_vocab.stoi['<eos>']:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1566', '<eos>']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, _ = predict('13112 16042 3871 35', src_vocab, src_vocab, model, device)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:04, 12.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05807317614020755"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_map(model, valid_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sequences from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364695it [00:02, 146284.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 48709 user interactions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-ed1502153b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Read {len(User)} user interactions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mall_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_prod_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "colsep = \"\\t\"\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_ids(elems):\n",
    "    ids = []\n",
    "    for ii, e in enumerate(elems):\n",
    "        if e not in prod_dict[ii]:\n",
    "            prod_dict[ii][e] = len(prod_dict[ii]) + 1\n",
    "        ids.append(prod_dict[ii][e])\n",
    "    return ids\n",
    "\n",
    "def break_sessions(seqs):    \n",
    "    sids = sorted(list(set([x[-1] for x in seqs])))\n",
    "    temp = [[] for _ in range(len(sids))]\n",
    "    for seq in seqs:\n",
    "        temp[seq[-1]].append(seq[:-1])\n",
    "    return temp\n",
    "\n",
    "inp_file = os.path.join(data_dir, file_name)\n",
    "sample = pd.read_csv(inp_file, sep=colsep, nrows=5)\n",
    "ncol = sample.shape[1]\n",
    "\n",
    "num_prod_dim = ncol - 3  # other than u, i, t\n",
    "if num_prod_dim > 0:\n",
    "    prod_dict = [{} for _ in range(num_prod_dim)]\n",
    "\n",
    "User = defaultdict(list)\n",
    "with open(os.path.join(data_dir, file_name), 'r') as fr:\n",
    "    for line in tqdm(fr):\n",
    "        if ncol == 3:\n",
    "            u, i, _ = line.rstrip().split(colsep)\n",
    "        elif ncol >= 4:\n",
    "            elems = line.rstrip().split(colsep)\n",
    "            u, i, t = elems[0], elems[1], elems[-1]\n",
    "            pdims = elems[2:-1]\n",
    "            pids = get_ids(pdims)\n",
    "        u = int(u)\n",
    "        i = int(i)\n",
    "        t = int(t)\n",
    "        if ncol >= 4:\n",
    "            User[u].append([i] + pids + [t])\n",
    "        else:\n",
    "            User[u].append(i)\n",
    "print(f\"Read {len(User)} user interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seqs = {k: [] for k in range(num_prod_dim)}\n",
    "all_seqs['prod'] = []  # one more dictionary for the products\n",
    "\n",
    "for u in User:\n",
    "    seqs = break_sessions(User[u])\n",
    "    for ii in range(1, len(seqs)):\n",
    "        inp, tgt = seqs[ii-1], seqs[ii]\n",
    "        if len(inp) > inp_seq_len:\n",
    "            inp = inp[-inp_seq_len:] # taking the last 12\n",
    "        if len(tgt) > tgt_seq_len:\n",
    "            tgt = tgt[:tgt_seq_len]  # taking the first 12\n",
    "        inp_p = [str(ii[0]) for ii in inp]  # only the product-id\n",
    "        tgt_p = [str(ii[0]) for ii in tgt]  # always only the product-id\n",
    "        all_seqs['prod'].append((inp_p, tgt_p))\n",
    "        for jj in range(num_prod_dim):\n",
    "            inp_jj = [kk[jj+1] for kk in inp]\n",
    "            tgt_jj = [kk[jj+1] for kk in tgt]\n",
    "            all_seqs[jj].append((inp_jj, tgt_jj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1186'], ['13112', '16042', '3871', '35'])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_seqs['prod'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1], [2, 2, 3, 4]),\n",
       " ([1], [1, 1, 2, 1]),\n",
       " ([1], [2, 3, 3, 4]),\n",
       " ([1], [2, 3, 4, 5]),\n",
       " ([1], [2, 2, 3, 3]),\n",
       " ([1], [1, 1, 1, 1]),\n",
       " ([1], [1, 1, 1, 1]),\n",
       " ([1], [1, 1, 1, 1]),\n",
       " ([1], [2, 2, 3, 3])]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[all_seqs[kk][0] for kk in range(num_prod_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(prod_seqs, tokenizer, index=-1):\n",
    "    counter = Counter()\n",
    "    for seq in prod_seqs:\n",
    "        src, tgt = ' '.join(seq[0]), ' '.join(seq[1])\n",
    "        if index == -1:\n",
    "            counter.update(tokenizer(src))\n",
    "            counter.update(tokenizer(tgt))\n",
    "        else:\n",
    "            counter.update(tokenizer(seq[index]))\n",
    "    return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
    "\n",
    "def data_process(all_seqs, tokenizer, vocab, test_flag=False):\n",
    "    \"\"\"\n",
    "    all_seqs is a dict with keys: 'prod', 0, 1, ..., num_prod_dim-1\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    num_examples = len(all_seqs['prod'])\n",
    "    for ii in range(num_examples):\n",
    "        items = all_seqs['prod'][ii]\n",
    "        meta = [all_seqs[kk][ii][0] for kk in range(num_prod_dim)] # rest of the attributes for input\n",
    "        if test_flag:\n",
    "            src = items[0]\n",
    "            src_tensor = torch.tensor([vocab[token] for token in tokenizer(src)], dtype=torch.long)\n",
    "            meta_tensor = torch.tensor(meta)\n",
    "            data.append(src_tensor)\n",
    "        else:\n",
    "            src, tgt = items[0], items[1]\n",
    "            src_tensor = torch.tensor([vocab[token] for token in src], dtype=torch.long)\n",
    "            tgt_tensor = torch.tensor([vocab[token] for token in tgt], dtype=torch.long)\n",
    "            meta_tensor = torch.tensor(meta)\n",
    "            if src_tensor.dim() == 1:\n",
    "                src_tensor = torch.unsqueeze(src_tensor, 0)\n",
    "            src_tensor = torch.cat([src_tensor, meta_tensor])\n",
    "            data.append((src_tensor, tgt_tensor))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71460, 57168, 14292)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = build_vocab(all_seqs['prod'], tokenizer)\n",
    "all_data = data_process(all_seqs, tokenizer, src_vocab)\n",
    "train_data, val_data = train_test_split(all_data, test_size=0.2)\n",
    "# test_data = data_process(test_file_path, tokenizer, src_vocab, test_flag=True)\n",
    "len(all_data), len(train_data), len(val_data)#, len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71460"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (torch)",
   "language": "python",
   "name": "py37_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
