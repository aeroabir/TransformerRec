{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer seq2seq Model\n",
    "\n",
    "- Modified from https://github.com/bentrevett/pytorch-seq2seq\n",
    "- also useful: https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "\n",
    "import torchtext\n",
    "# from torchtext.legacy.datasets import Multi30k\n",
    "# from torchtext.legacy.data import Field, BucketIterator\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# import spacy\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformer_pyt import Encoder, Decoder, Seq2Seq, Seq2SeqMulti\n",
    "from transformer_pyt import train, evaluate\n",
    "from utils import (get_session_data, \n",
    "                   build_vocab_from_seqs, \n",
    "                   data_process_meta, \n",
    "                   data_process_no_meta,\n",
    "                   epoch_time,\n",
    "                   get_session_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0924243001',\n",
       " '0924243002',\n",
       " '0923758001',\n",
       " '0918522001',\n",
       " '0909370001',\n",
       " '0866731001',\n",
       " '0751471001',\n",
       " '0915529003',\n",
       " '0915529005',\n",
       " '0448509014',\n",
       " '0762846027',\n",
       " '0714790020']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/recsys_data/RecSys/h_and_m_personalized_fashion_recommendation\"\n",
    "file_name = \"hnm_3w_sessionized_orig.txt\" # \"hnm_big.txt\", \"hnm_3w_sessionized.txt\", \"hnm_7w_sessionized.txt\"\n",
    "model_name = file_name.split(\".\")[0] + \".pt\"\n",
    "seq_file_name = \"seq_\" + file_name\n",
    "test_seq_file = \"seq_test_\" + file_name\n",
    "colsep = \"\\t\"\n",
    "include_meta = False\n",
    "\n",
    "inp_seq_len, tgt_seq_len = 12, 12\n",
    "BATCH_SIZE = 256\n",
    "num_examples = None\n",
    "file_path = os.path.join(data_dir, seq_file_name)\n",
    "model_path = os.path.join(data_dir, model_name)\n",
    "test_file_path = os.path.join(data_dir, test_seq_file)\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "# en_tokenizer = get_tokenizer(language='en')\n",
    "\n",
    "tokens = tokenizer('0924243001 0924243002 0923758001 0918522001 0909370001 0866731001 0751471001 0915529003 0915529005 0448509014 0762846027 0714790020')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the sequence information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364695it [00:01, 210909.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 48709 user interactions\n",
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 'prod'])\n"
     ]
    }
   ],
   "source": [
    "inp_file = os.path.join(data_dir, file_name)\n",
    "\n",
    "all_seqs, prod_dict = get_session_data(inp_file, \n",
    "                                       inp_seq_len=inp_seq_len,\n",
    "                                       tgt_seq_len=tgt_seq_len,\n",
    "                                       convert_to_integer=False)\n",
    "print(all_seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0921073001'], ['0777148006', '0835801001', '0923134005', '0865929003'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_seqs['prod'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 21533 words in the vocabulary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(71460, 57168, 14292)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = build_vocab_from_seqs(all_seqs['prod'], tokenizer)\n",
    "print(f\"Total {len(src_vocab)} words in the vocabulary\")\n",
    "\n",
    "if include_meta:\n",
    "    all_data = data_process_meta(all_seqs, tokenizer, src_vocab)\n",
    "else:\n",
    "    all_data = data_process_no_meta(all_seqs, src_vocab)\n",
    "train_data, val_data = train_test_split(all_data, test_size=0.2)\n",
    "# test_data = data_process(test_file_path, tokenizer, src_vocab, test_flag=True)\n",
    "len(all_data), len(train_data), len(val_data)#, len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['<unk>'], src_vocab['<pad>'], src_vocab['<bos>'], src_vocab['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 21533)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab['921073001'], src_vocab['777148006'], len(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13867,  4365,   822,  5939,   625,  2707,   754,  8904,  2454]),\n",
       " tensor([51]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Product Vector - Separately Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105542, 50) 105542\n"
     ]
    }
   ],
   "source": [
    "pv_file = os.path.join(data_dir, \"prod_vectors.pkl\")\n",
    "with open(pv_file, \"rb\") as fr:\n",
    "    prod_vec, prod_list = pickle.load(fr)\n",
    "print(prod_vec.shape, len(prod_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "embed_matrix = np.zeros((len(src_vocab), prod_vec.shape[1]))\n",
    "count = 0\n",
    "for tok, idx in src_vocab.stoi.items():\n",
    "    if tok in prod_list:\n",
    "        list_index = prod_list.index(tok)\n",
    "        embed_matrix[idx] = prod_vec[list_index]\n",
    "    else:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = src_vocab['<pad>']\n",
    "BOS_IDX = src_vocab['<bos>']\n",
    "EOS_IDX = src_vocab['<eos>']\n",
    "\n",
    "if include_meta:\n",
    "    def generate_batch(data_batch):\n",
    "        inp_batch, tgt_batch = [], []\n",
    "        for (de_item, en_item) in data_batch:\n",
    "            n = de_item.shape[0]\n",
    "            before = torch.unsqueeze(torch.tensor([BOS_IDX] * n), 1)\n",
    "            after = torch.unsqueeze(torch.tensor([EOS_IDX] * n), 1)\n",
    "            total = torch.cat([before, de_item, after], dim=1)\n",
    "            total = total.permute(1, 0)\n",
    "            inp_batch.append(total)\n",
    "            tgt_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "\n",
    "        inp_batch = pad_sequence(inp_batch, padding_value=PAD_IDX)\n",
    "        tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "        return inp_batch, tgt_batch\n",
    "\n",
    "    # input dimension of each product attribute\n",
    "    prod_dict_dims = [max(prod_dict[k].values()) for k in range(len(prod_dict))]\n",
    "\n",
    "else:\n",
    "    def generate_batch(data_batch):\n",
    "        de_batch, en_batch = [], []\n",
    "        for (de_item, en_item) in data_batch:\n",
    "            de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "            en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "        en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "        return de_batch, en_batch\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iterator = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create multiple encoders - one for each product attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = 0\n",
    "TRG_PAD_IDX = 0\n",
    "\n",
    "if include_meta:\n",
    "    HID_DIM = 128\n",
    "    HID_DIM2 = 32\n",
    "    ENC_LAYERS = 2\n",
    "    DEC_LAYERS = 2\n",
    "    ENC_HEADS = 8\n",
    "    DEC_HEADS = 8\n",
    "    ENC_PF_DIM = 128\n",
    "    DEC_PF_DIM = 128\n",
    "    ENC_DROPOUT = 0.1\n",
    "    DEC_DROPOUT = 0.1\n",
    "    OUTPUT_DIM = len(src_vocab)\n",
    "\n",
    "    encs = torch.nn.ModuleList()\n",
    "    prod_enc = Encoder(input_dim=len(src_vocab), \n",
    "                       hid_dim=HID_DIM, \n",
    "                       n_layers=ENC_LAYERS, \n",
    "                       n_heads=ENC_HEADS, \n",
    "                       pf_dim=ENC_PF_DIM, \n",
    "                       dropout=ENC_DROPOUT, \n",
    "                       device=device)\n",
    "    encs.append(prod_enc)\n",
    "    total_dim = HID_DIM\n",
    "    for pdim in prod_dict_dims:\n",
    "        enc_p = Encoder(input_dim=pdim, \n",
    "                       hid_dim=HID_DIM2, \n",
    "                       n_layers=ENC_LAYERS, \n",
    "                       n_heads=ENC_HEADS, \n",
    "                       pf_dim=ENC_PF_DIM, \n",
    "                       dropout=ENC_DROPOUT, \n",
    "                       device=device)\n",
    "        encs.append(enc_p)\n",
    "        total_dim += HID_DIM2\n",
    "\n",
    "    dec = Decoder(OUTPUT_DIM, \n",
    "                  HID_DIM, \n",
    "                  DEC_LAYERS, \n",
    "                  DEC_HEADS, \n",
    "                  DEC_PF_DIM, \n",
    "                  DEC_DROPOUT, \n",
    "                  device)\n",
    "    model = Seq2SeqMulti(encs, dec, total_dim, HID_DIM, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)    \n",
    "else:\n",
    "    INPUT_DIM = len(src_vocab)\n",
    "    OUTPUT_DIM = len(src_vocab)\n",
    "    HID_DIM = 256\n",
    "    ENC_LAYERS = 3\n",
    "    DEC_LAYERS = 3\n",
    "    ENC_HEADS = 8\n",
    "    DEC_HEADS = 8\n",
    "    ENC_PF_DIM = 512\n",
    "    DEC_PF_DIM = 512\n",
    "    ENC_DROPOUT = 0.1\n",
    "    DEC_DROPOUT = 0.1\n",
    "\n",
    "    enc = Encoder(INPUT_DIM, \n",
    "                  HID_DIM, \n",
    "                  ENC_LAYERS, \n",
    "                  ENC_HEADS, \n",
    "                  ENC_PF_DIM, \n",
    "                  ENC_DROPOUT, \n",
    "                  device,\n",
    "                  pretrained=True,\n",
    "                  weight=torch.FloatTensor(embed_matrix),  # has to be converted\n",
    "                  ext_embed_dim=embed_matrix.shape[1])\n",
    "\n",
    "    dec = Decoder(OUTPUT_DIM, \n",
    "                  HID_DIM, \n",
    "                  DEC_LAYERS, \n",
    "                  DEC_HEADS, \n",
    "                  DEC_PF_DIM, \n",
    "                  DEC_DROPOUT, \n",
    "                  device)\n",
    "    model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,064,349 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        \n",
    "model.apply(initialize_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of steps per epoch: 223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.97it/s]\n",
      "56it [00:05, 11.10it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 1s | patience 1\n",
      "\tTrain Loss: 4.959 | Train PPL: 142.424\n",
      "\t Val. Loss: 2.144 |  Val. PPL:   8.534 | Val. MAP:   0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.96it/s]\n",
      "56it [00:05, 11.04it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 1m 1s | patience 2\n",
      "\tTrain Loss: 2.018 | Train PPL:   7.522\n",
      "\t Val. Loss: 1.969 |  Val. PPL:   7.164 | Val. MAP:   0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.95it/s]\n",
      "56it [00:05, 10.92it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 1m 1s | patience 0\n",
      "\tTrain Loss: 1.950 | Train PPL:   7.029\n",
      "\t Val. Loss: 1.951 |  Val. PPL:   7.039 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.96it/s]\n",
      "56it [00:05, 10.93it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 1m 1s | patience 1\n",
      "\tTrain Loss: 1.920 | Train PPL:   6.824\n",
      "\t Val. Loss: 1.957 |  Val. PPL:   7.079 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.95it/s]\n",
      "56it [00:05, 10.79it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 1m 1s | patience 2\n",
      "\tTrain Loss: 1.895 | Train PPL:   6.656\n",
      "\t Val. Loss: 1.953 |  Val. PPL:   7.053 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.94it/s]\n",
      "56it [00:05, 10.82it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 1m 2s | patience 3\n",
      "\tTrain Loss: 1.870 | Train PPL:   6.489\n",
      "\t Val. Loss: 1.955 |  Val. PPL:   7.064 | Val. MAP:   0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.93it/s]\n",
      "56it [00:05, 10.86it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.838 | Train PPL:   6.282\n",
      "\t Val. Loss: 1.956 |  Val. PPL:   7.070 | Val. MAP:   0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.95it/s]\n",
      "56it [00:05, 10.80it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 1m 1s | patience 0\n",
      "\tTrain Loss: 1.812 | Train PPL:   6.120\n",
      "\t Val. Loss: 1.954 |  Val. PPL:   7.060 | Val. MAP:   0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.92it/s]\n",
      "56it [00:05, 10.95it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.779 | Train PPL:   5.923\n",
      "\t Val. Loss: 1.961 |  Val. PPL:   7.105 | Val. MAP:   0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.93it/s]\n",
      "56it [00:05, 10.91it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.747 | Train PPL:   5.739\n",
      "\t Val. Loss: 1.964 |  Val. PPL:   7.127 | Val. MAP:   0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.94it/s]\n",
      "56it [00:05, 10.88it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.717 | Train PPL:   5.566\n",
      "\t Val. Loss: 1.966 |  Val. PPL:   7.144 | Val. MAP:   0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.92it/s]\n",
      "56it [00:05, 10.92it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.686 | Train PPL:   5.399\n",
      "\t Val. Loss: 1.967 |  Val. PPL:   7.151 | Val. MAP:   0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.92it/s]\n",
      "56it [00:05, 10.87it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.656 | Train PPL:   5.236\n",
      "\t Val. Loss: 1.965 |  Val. PPL:   7.135 | Val. MAP:   0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.92it/s]\n",
      "56it [00:05, 10.91it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.628 | Train PPL:   5.092\n",
      "\t Val. Loss: 1.977 |  Val. PPL:   7.220 | Val. MAP:   0.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.94it/s]\n",
      "56it [00:05, 10.64it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Time: 1m 2s | patience 1\n",
      "\tTrain Loss: 1.600 | Train PPL:   4.955\n",
      "\t Val. Loss: 1.986 |  Val. PPL:   7.284 | Val. MAP:   0.016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.94it/s]\n",
      "56it [00:05, 10.91it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.572 | Train PPL:   4.816\n",
      "\t Val. Loss: 1.990 |  Val. PPL:   7.315 | Val. MAP:   0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.93it/s]\n",
      "56it [00:05, 10.66it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.545 | Train PPL:   4.687\n",
      "\t Val. Loss: 1.994 |  Val. PPL:   7.346 | Val. MAP:   0.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.93it/s]\n",
      "56it [00:05, 10.82it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Time: 1m 2s | patience 1\n",
      "\tTrain Loss: 1.518 | Train PPL:   4.562\n",
      "\t Val. Loss: 2.007 |  Val. PPL:   7.444 | Val. MAP:   0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:56,  3.93it/s]\n",
      "56it [00:05, 10.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.492 | Train PPL:   4.444\n",
      "\t Val. Loss: 2.015 |  Val. PPL:   7.503 | Val. MAP:   0.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [00:57,  3.92it/s]\n",
      "56it [00:05, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Time: 1m 2s | patience 0\n",
      "\tTrain Loss: 1.464 | Train PPL:   4.324\n",
      "\t Val. Loss: 2.017 |  Val. PPL:   7.514 | Val. MAP:   0.049\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "N_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-04\n",
    "CLIP = 1\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_map = 0\n",
    "patience, max_patience = 0, 5\n",
    "\n",
    "print(f\"Number of steps per epoch: {len(train_data)//BATCH_SIZE}\")\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, device)\n",
    "    valid_loss, valid_map = evaluate(model, valid_iterator, criterion, device)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_map > best_valid_map:\n",
    "        best_valid_map = valid_map\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "\n",
    "    if patience == max_patience:\n",
    "        print(\"Maximum patience reached ... exiting!\")\n",
    "        break\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s | patience {patience}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f} | Val. MAP: {valid_map:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hnm_7w_sessionized.txt'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the test data - last session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1332519it [00:05, 227087.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 144202 user interactions\n",
      "10 dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 'prod'])\n"
     ]
    }
   ],
   "source": [
    "test_seqs = get_session_data_test(inp_file, prod_dict, inp_seq_len=inp_seq_len)\n",
    "print(len(test_seqs), test_seqs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144202"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data_process_meta(test_seqs, tokenizer, src_vocab, test_flag=True)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_test(data_batch):\n",
    "    inp_batch = []\n",
    "    for de_item in data_batch:\n",
    "        n = de_item.shape[0]\n",
    "        before = torch.unsqueeze(torch.tensor([BOS_IDX] * n), 1)\n",
    "        after = torch.unsqueeze(torch.tensor([EOS_IDX] * n), 1)\n",
    "        total = torch.cat([before, de_item, after], dim=1)\n",
    "        total = total.permute(1, 0)\n",
    "        inp_batch.append(total)\n",
    "    \n",
    "#     print(torch.cat(inp_batch, dim=0).shape)\n",
    "    inp_batch = pad_sequence(inp_batch, padding_value=PAD_IDX)\n",
    "    return inp_batch\n",
    "\n",
    "test_iterator = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-702649ad46e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trg' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "epoch_loss = 0\n",
    "all_maps = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for _, src in tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = src.to(device)\n",
    "        # make the batch dimension first\n",
    "        if src.dim() == 3:\n",
    "            src = src.permute(1, 0, 2)\n",
    "        else:\n",
    "            src = src.permute(1, 0)\n",
    "\n",
    "        output, _ = model(src, trg[:, :-1])\n",
    "        prediction = torch.argmax(output, axis=-1)\n",
    "        print(prediction.shape)\n",
    "        sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(src_tensor, model, vocab, device, max_len = 50):\n",
    "    \"\"\"\n",
    "    inp: (b, s, f), batch_size X sequence length X feature dimension\n",
    "    \"\"\"\n",
    "    src_tensor = src_tensor.unsqueeze(0).to(device)  # add the batch dimension\n",
    "    \n",
    "    model.eval()\n",
    "    src_mask = model.make_src_mask(src_tensor[:, :, 0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = []\n",
    "        for ii in range(model.num_features):\n",
    "            enc_src.append(model.encoders[ii](src_tensor[:, :, ii], src_mask))\n",
    "        enc_src = torch.cat(enc_src, dim=-1)\n",
    "        enc_src = model.linear(enc_src)\n",
    "\n",
    "    trg_indexes = [vocab.stoi['<bos>']]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == vocab.stoi['<eos>']:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [vocab.itos[i] for i in trg_indexes]\n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['220', '<eos>']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, _ = translate_sentence(src[4, :, :], model, src_vocab, device, max_len = tgt_seq_len)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Product Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71460, 57168, 14292, 48709)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = build_vocab_from_file(file_path, tokenizer)\n",
    "all_data = data_process(file_path, tokenizer, src_vocab)\n",
    "train_data, val_data = train_test_split(all_data, test_size=0.2)\n",
    "test_data = data_process(test_file_path, tokenizer, src_vocab, test_flag=True)\n",
    "len(all_data), len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(src_vocab)\n",
    "OUTPUT_DIM = len(src_vocab)\n",
    "HID_DIM = 256\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 8\n",
    "DEC_HEADS = 8\n",
    "ENC_PF_DIM = 512\n",
    "DEC_PF_DIM = 512\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = src_vocab['<pad>']\n",
    "BOS_IDX = src_vocab['<bos>']\n",
    "EOS_IDX = src_vocab['<eos>']\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    de_batch, en_batch = [], []\n",
    "    for (de_item, en_item) in data_batch:\n",
    "        de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    return de_batch, en_batch\n",
    "\n",
    "train_iterator = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "valid_iterator = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
    "                        shuffle=True, collate_fn=generate_batch)\n",
    "test_iterator = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
    "                       shuffle=False, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = 0\n",
    "TRG_PAD_IDX = 0\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, src_vocab, trg_vocab, model, device, max_len = tgt_seq_len):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    tokens = tokenizer(sentence)\n",
    "    tokens = [src_vocab['<bos>']] + tokens + [src_vocab['<eos>']]\n",
    "    src_indexes = [src_vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask)\n",
    "\n",
    "    trg_indexes = [trg_vocab.stoi['<bos>']]\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == trg_vocab.stoi['<eos>']:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1566', '<eos>']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, _ = predict('13112 16042 3871 35', src_vocab, src_vocab, model, device)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (torch)",
   "language": "python",
   "name": "py37_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
